{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPxT/cNwhKG3dSor4+JPndQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nallagondu/DATASCIENCE-practice/blob/main/Gradient_Boosted_Trees_Continue__18022024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKipYYiWPYbu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as  sns\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "#sns.set_style(\"whitegrid\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_csv(\"heart_disease.csv\")\n",
        "url = \"https://raw.githubusercontent.com/nallagondu/datatrained-training-ml-Files/main/heart_disease.csv\"\n",
        "# Read the CSV file from the URL\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "df.head()"
      ],
      "metadata": {
        "id": "zQAiVssFPsWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('Unnamed: 0', axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "4anJVO-mPvnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "RqtxBrs-PzhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "I_NTZbCvQNiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "Pue536SEQfwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Just find correlation of feature vs target using corrwith\n",
        "df.drop('target',axis = 1).corrwith(df.target)"
      ],
      "metadata": {
        "id": "kLjsBzXbP3uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# Visualize the correlation**"
      ],
      "metadata": {
        "id": "n-30CyR0RLAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('target', axis=1).corrwith(df.target).plot(kind='bar',grid=True, figsize=(8,5),title='Correlation with target')"
      ],
      "metadata": {
        "id": "k0DcCKcfQmps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets work on feture selection and see if that can help us building better model"
      ],
      "metadata": {
        "id": "i8yPkTi4Sj8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model building using selectPrecentile features\n",
        "\n",
        "\n",
        "Using SelectPercentile features is a feature selection technique that selects the top k percentile of features with the highest scores based on a specified statistical test (e.g., chi-squared test, ANOVA F-test). Here's how you can build a model using SelectPercentile features:\n",
        "\n",
        "**Data Preparation:**\n",
        "\n",
        "Prepare your dataset by encoding categorical variables, handling missing values, and scaling numerical features if necessary.\n",
        "**Feature Selection:**\n",
        "\n",
        "Import SelectPercentile from sklearn.feature_selection.\n",
        "Initialize SelectPercentile with the desired statistical test (e.g., chi2 for classification tasks, f_classif for regression tasks) and the desired percentile of features to keep.\n",
        "Fit SelectPercentile to your training data to compute the scores and select the top percentile of features.\n",
        "**Model Building:**\n",
        "\n",
        "Import the necessary model class (e.g., LogisticRegression, RandomForestClassifier, GradientBoostingRegressor) from sklearn.\n",
        "Initialize the model with any desired hyperparameters.\n",
        "Concatenate the selected features obtained from SelectPercentile with the corresponding target variable (if applicable) to create the training dataset.\n",
        "Split the data into training and testing sets using train_test_split from sklearn.model_selection.\n",
        "Fit the model to the training data and evaluate its performance on the testing data.\n",
        "\n",
        "\n",
        "\n",
        "#chi2 (Chi-squared)\n",
        "\n",
        " Is a statistical test used to determine the independence between two categorical variables in a dataset. In the context of feature selection, the chi-squared test measures the dependency between each feature and the target variable in a classification problem.\n",
        "\n",
        "**Here's how chi-squared feature selection works:**\n",
        "\n",
        "For each feature, the chi-squared test computes the chi-squared statistic and corresponding p-value between the feature and the target variable.\n",
        "The chi-squared statistic measures the extent of the relationship between the feature and the target. A higher chi-squared statistic indicates a stronger association between the feature and the target.\n",
        "The p-value represents the probability of observing the chi-squared statistic under the null hypothesis that the feature and the target are independent. A lower p-value suggests that the feature is unlikely to be independent of the target.\n",
        "Features with high chi-squared statistics and low p-values are considered to be more informative and are selected for inclusion in the model.\n",
        "In scikit-learn, the chi-squared test is commonly used for feature selection in classification tasks through the SelectKBest or SelectPercentile feature selection methods. The chi2 function from sklearn.feature_selection module is used to compute the chi-squared statistics and p-values."
      ],
      "metadata": {
        "id": "wsRbkCozYYDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectPercentile, chi2"
      ],
      "metadata": {
        "id": "t5PwUQcAYV79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiate selectPercentile and fit (feature and  label)\n",
        "X = df.drop(['target'], axis=1)\n",
        "y = df.target\n",
        "\n",
        "SPercentile = SelectPercentile(score_func=chi2, percentile=80)\n",
        "\n",
        "# Fit and transform the feature matrix X\n",
        "X_selected = SPercentile.fit_transform(X, y)"
      ],
      "metadata": {
        "id": "ZHl2TpSOZVXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Seperate the features to check  p-values\n",
        "cols = SPercentile.get_support(indices=True)  # to teturn index number insted of boolean\n",
        "print('Feature Indexx = ',cols)\n",
        "\n",
        "features = X.columns[cols]\n",
        "print('features = ', list(features))"
      ],
      "metadata": {
        "id": "3FsZaCVSauUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores = pd.DataFrame({'features': X.columns, 'Chi2Score': SPercentile.scores_, 'pValue': SPercentile.pvalues_})\n",
        "df_scores.sort_values(by='Chi2Score', ascending=False)"
      ],
      "metadata": {
        "id": "RKSoMu9rbjwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create subset of selected features\n",
        "X = df[features]\n",
        "y = df.target"
      ],
      "metadata": {
        "id": "P67HyBP5c7GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import Libs\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaler = scaler.fit_transform(X)\n",
        "x_train,x_test,y_train,y_test = train_test_split(X_scaler,y ,test_size = 0.3 ,random_state=43)"
      ],
      "metadata": {
        "id": "3bB0DePbfntr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pOFcyXw2f1BP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GradientBoosting Classifier**\n",
        "\n"
      ],
      "metadata": {
        "id": "zSEkuZaJgo9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier # if it is regressior use GradientBoostingregressior\n",
        "from sklearn.metrics import classification_report, accuracy_score\n"
      ],
      "metadata": {
        "id": "cXi4Ymm5fOqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metric_score(clf, x_train,x_test,y_train,y_test, train= True):\n",
        "  if train:\n",
        "    y_pred = clf.predict(x_train)\n",
        "    print(\"\\n  _____Train result____\")\n",
        "    print(f\"Accuracy Score: {accuracy_score(y_train,y_pred) * 100: .2f}%\")\n",
        "  elif train==False:\n",
        "    pred = clf.predict(x_test)\n",
        "    print(\"\\n  _____Test result____\")\n",
        "    print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100: .2f}%\")\n",
        "\n",
        "    print('\\n \\n  test classification report \\n', classification_report(y_test, pred,digits = 2))\n"
      ],
      "metadata": {
        "id": "45Bpo73GfiwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initiate GradientBoosting Classifier\n",
        "gbdt_clf =  GradientBoostingClassifier()\n",
        "gbdt_clf.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "OIE1GBj1i3V2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_score(gbdt_clf,x_train,x_test,y_train,y_test,train=True)\n",
        "metric_score(gbdt_clf,x_train,x_test,y_train,y_test,train=False)"
      ],
      "metadata": {
        "id": "ICVwvgowjU4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lets try if we can improve the performacne of our model using parameter tunings**\n",
        "\n",
        "#Hyperparameter tuning ..."
      ],
      "metadata": {
        "id": "LtkiefvDkNuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "q1e5BTcHkNE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_param = {\n",
        "    'max_depth': range(4,8),\n",
        "    'min_samples_split': range(2,8,2),\n",
        "    'n_estimators': range(20,200,10),\n",
        "    'learning_rate': np.arange(0.1,0.3)\n",
        "}"
      ],
      "metadata": {
        "id": "f81POXBAknqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid = RandomizedSearchCV(GradientBoostingClassifier(),cv=5,param_distributions=grid_param)\n",
        "grid.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "6o_Cn3BXlN8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid.best_params_"
      ],
      "metadata": {
        "id": "DVpKU1UZlgfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbdt_clf = GradientBoostingClassifier(\n",
        "    max_depth =7, min_samples_split = 6 ,n_estimators=170,learning_rate=0.1)\n",
        "\n",
        "gbdt_clf.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "Ak9cqQbfltgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_score(gbdt_clf,x_train,x_test,y_train,y_test,train=True)\n",
        "metric_score(gbdt_clf,x_train,x_test,y_train,y_test,train=False)"
      ],
      "metadata": {
        "id": "cvoMFu7Fmy6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Still have chance to ture the parameters with different range and try to improve the score\n"
      ],
      "metadata": {
        "id": "5HAe_Fbtm6s_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GBDT end"
      ],
      "metadata": {
        "id": "obOO3T-gnjqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ds  most of the fetures are catagerical  then need to use CAT boost ...learn and research\n",
        "#What is cat and what is boost"
      ],
      "metadata": {
        "id": "-nsmBPHXm6KZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3DtYTzeyoSOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We have Cat boost model for anotther model ----"
      ],
      "metadata": {
        "id": "6WGUNd-toS6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continue :\n",
        " XGB_used_car_get_dummies_18022024.ipynb"
      ],
      "metadata": {
        "id": "mz8TqaGrofFd"
      }
    }
  ]
}