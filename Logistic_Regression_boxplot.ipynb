{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoea47TsEvp7jkm3GzBwbY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nallagondu/DATASCIENCE-practice/blob/main/Logistic_Regression_boxplot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEPBsPT0xTtA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic regression** is a process of modeling the probability of a discrete outcome given an input variable. The most common logistic regression models a binary outcome; something that can take two values such as true/false, yes/no, and so on.\n",
        "\n",
        "**Logistic regression**\n",
        "Logistic regression, despite its name, is a classification model rather than regression model. Logistic regression is a simple and more efficient method for binary and linear classification problems. It is a classification model, which is very easy to realize and achieves very good performance with linearly separable classes. It is an extensively employed algorithm for classification in industry. The logistic regression model, like the Adaline and perceptron, is a statistical method for binary classification that can be generalized to multiclass classification. Scikit-learn has a highly optimized version of logistic regression implementation, which supports multiclass classification task (Raschka, 2015)."
      ],
      "metadata": {
        "id": "FAJW9Gzvxoxx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7qFUHPC5x5av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**why we are not using Linear regression model for Classification problems**\n",
        "Linear regression models are not typically used for classification problems because they are not designed to handle categorical outcomes.\n",
        "\n",
        "Here are a few reasons why linear regression is not suitable for classification problems:\n",
        "\n",
        "**Output Range:** Linear regression predicts continuous values, which can span a wide range of real numbers. In classification problems, however, the output is typically categorical (e.g., binary classes like \"yes\" or \"no\", or multi-class labels like \"cat\", \"dog\", \"horse\"). Using linear regression could produce predictions outside the valid range of the target classes, leading to nonsensical results.\n",
        "\n",
        "**Assumption Violation**: Linear regression assumes that the relationship between the independent variables and the dependent variable is linear. This may not hold true for classification problems where the decision boundaries between classes could be nonlinear.\n",
        "\n",
        "**Interpretation Difficulty:** In classification, the focus is often on probabilities or class membership rather than predicting a specific continuous value. Linear regression outputs do not directly represent probabilities, making interpretation for classification problematic.\n",
        "\n",
        "**Sensitive to Outliers:** Linear regression can be sensitive to outliers, and in classification problems, outliers may have a more significant impact on the decision boundary, potentially leading to misclassification.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The sigmoid function, also known as the logistic function, is a mathematical function commonly used in machine learning and statistics. It maps any real-valued number to a value between 0 and 1. The sigmoid function is defined as:\n",
        "\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "�\n",
        "−\n",
        "�\n",
        "σ(z)=\n",
        "1+e\n",
        "−z\n",
        "\n",
        "1\n",
        "​\n",
        "\n",
        "\n",
        "Where:\n",
        "\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "σ(z) is the output or the value of the sigmoid function.\n",
        "�\n",
        "z is the input, which can be any real number.\n",
        "The sigmoid function has the following properties:\n",
        "\n",
        "Range: The output of the sigmoid function is always in the range\n",
        "[\n",
        "0\n",
        ",\n",
        "1\n",
        "]\n",
        "[0,1], which makes it suitable for binary classification tasks where probabilities are needed.\n",
        "\n",
        "Smoothness: The sigmoid function is smooth and continuously differentiable, which makes it suitable for optimization algorithms like gradient descent.\n",
        "\n",
        "S-shape: The sigmoid function has an S-shaped curve. This property allows it to model non-linear relationships between variables.\n",
        "\n",
        "Asymptotes: As\n",
        "�\n",
        "z approaches positive infinity,\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "σ(z) approaches 1, and as\n",
        "�\n",
        "z approaches negative infinity,\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "σ(z) approaches 0. This property is useful for interpreting the output of the sigmoid function as probabilities.\n",
        "\n",
        "The sigmoid function is commonly used as the activation function in the output layer of binary classification neural networks, where it transforms the raw output of the network into probabilities of belonging to a particular class (e.g., class 1 vs. class 0). It's also used in logistic regression models, where it models the probability of the dependent variable belonging to a certain class given the independent variables."
      ],
      "metadata": {
        "id": "pwUDoYwyyN65"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h7jRt6CtyydD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation of a classification model**\n",
        "\n",
        "Evaluation of a classification model involves assessing its performance and how well it predicts the correct class labels for the given data. There are several metrics commonly used for evaluating classification models, including:\n",
        "\n",
        "**Accuracy:** Accuracy measures the proportion of correctly classified instances out of the total instances. It is calculated as:\n",
        "Accuracy=\n",
        "Number of Correct Predictions/Total Number of Predictions\n",
        "\n",
        "**Precision:** Precision measures the proportion of true positive predictions out of all positive predictions made by the model. It is calculated as:\n",
        "\n",
        "Precision= True Positives/\n",
        "True Positives+False Positives\n",
        "\n",
        "​\n",
        "\n",
        "\n",
        "**Recall (Sensitivity)**: Recall measures the proportion of true positive predictions out of all actual positive instances in the data. It is calculated as:\n",
        "Recall= True Positives/\n",
        "True Positives+False Negatives\n",
        "\n",
        "**F1 Score:** The F1 score is the harmonic mean of precision and recall. It provides a balance between precision and recall and is useful when the class distribution is imbalanced. It is calculated as:\n",
        "F1 Score=2× Precision×Recall/\n",
        "Precision+Recall\n",
        "\n",
        "**Specificity:** Specificity measures the proportion of true negative predictions out of all actual negative instances in the data. It is calculated as:\n",
        "Specificity= True Negatives/\n",
        "True Negatives+False Positives\n",
        "\n",
        "**ROC Curve (Receiver Operating Characteristic Curve):** The ROC curve is a graphical plot that illustrates the trade-off between the true positive rate (sensitivity) and the false positive rate (1 - specificity) for different threshold values. The area under the ROC curve (AUC-ROC) is also commonly used as a metric to evaluate the overall performance of a classification model.\n",
        "\n",
        "Confusion Matrix: A confusion matrix is a table that summarizes the performance of a classification model. It provides a breakdown of the number of true positive, true negative, false positive, and false negative predictions made by the model.\n",
        "\n",
        "The choice of evaluation metric depends on the specific characteristics of the classification problem and the priorities of the stakeholders. For example, in a highly imbalanced dataset, accuracy may not be an informative metric, and metrics like precision, recall, and F1 score may be more appropriate. Similarly, in applications where the cost of false positives and false negatives differs, metrics like precision-recall curves may provide more insight into the model's performance."
      ],
      "metadata": {
        "id": "jYlXiCNBzmZN"
      }
    }
  ]
}